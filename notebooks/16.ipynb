{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecb846c",
   "metadata": {},
   "source": [
    "# Step 16: In-Memory Vector Store Cache\n",
    "\n",
    "This notebook demonstrates caching LLM responses using in-memory vector store with semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from collections.abc import Awaitable, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Annotated\n",
    "from uuid import uuid4\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.embedding_generator_base import EmbeddingGeneratorBase\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "from semantic_kernel.connectors.in_memory import InMemoryStore\n",
    "from semantic_kernel.data.vector import (\n",
    "    VectorStoreField,\n",
    "    vectorstoremodel,\n",
    "    FieldTypes,\n",
    "    VectorSearchOptions,\n",
    "    VectorStore,\n",
    "    VectorStoreCollection,\n",
    ")\n",
    "from semantic_kernel.filters import (\n",
    "    FilterTypes,\n",
    "    FunctionInvocationContext,\n",
    "    PromptRenderContext,\n",
    ")\n",
    "from semantic_kernel.functions import FunctionResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c7c3b",
   "metadata": {},
   "source": [
    "## Define Cache Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorstoremodel\n",
    "@dataclass\n",
    "class CacheRecord:\n",
    "    prompt: Annotated[str, VectorStoreField(is_indexed=True)]\n",
    "    result: Annotated[str, VectorStoreField(is_full_text_indexed=True)]\n",
    "    prompt_embedding: Annotated[\n",
    "        list[float], VectorStoreField(field_type=FieldTypes.VECTOR, dimensions=1536)\n",
    "    ] = field(default_factory=list)\n",
    "    id: Annotated[str, VectorStoreField(field_type=FieldTypes.KEY)] = field(\n",
    "        default_factory=lambda: str(uuid4())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fb8a9",
   "metadata": {},
   "source": [
    "Refer to [steps/16.py](../steps/16.py) for the complete implementation with:\n",
    "- Prompt cache filter\n",
    "- Function invocation cache\n",
    "- Vector-based semantic caching\n",
    "- Performance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56058822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize kernel and services\n",
    "kernel = Kernel()\n",
    "chat = AzureChatCompletion(service_id=\"default\")\n",
    "embedding = AzureTextEmbedding(service_id=\"embedder\")\n",
    "kernel.add_service(chat)\n",
    "kernel.add_service(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create in-memory vector store\n",
    "vector_store = InMemoryStore()\n",
    "print(\"Vector store initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "async def execute_async(title: str, prompt: str):\n",
    "    print(f\"{title}: {prompt}\")\n",
    "    start = time.time()\n",
    "    result = await kernel.invoke_prompt(prompt)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"\\tElapsed Time: {elapsed:.3f}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ea4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "result = await execute_async(\"Test\", \"What's the tallest building in New York?\")\n",
    "print(f\"Result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
